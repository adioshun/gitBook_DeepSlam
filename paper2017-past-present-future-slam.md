|ë…¼ë¬¸ëª… |Past, Present, and Future of Simultaneous Localization And Mapping: Towards the Robust-Perception Age |
| --- | --- |
| ì €ì\(ì†Œì†\) | Cesar Cadena\( ETH Zurich\), L. Carlone(MIT) \) |
| í•™íšŒ/ë…„ë„ | arXiv Jun 2016~Jan 2017, [ë…¼ë¬¸](https://arxiv.org/abs/1606.05830) |
| Citation ID / í‚¤ì›Œë“œ | |
| ë°ì´í„°ì…‹(ì„¼ì„œ)/ëª¨ë¸ | |
| ê´€ë ¨ì—°êµ¬||
| ì°¸ê³  |[í™ˆí˜ì´ì§€](https://slam-future.github.io/) |
| ì½”ë“œ | |


# Past, Present, and Future of Simultaneous Localization And Mapping


- We survey the current state of SLAM and consider future directions


- We start by presenting what is now the de-facto standard formulation for SLAM. 


- ê´€ë ¨ì—°êµ¬ : We then review related work, covering a broad set of topics including 


----------


    - robustness and scalability in long-term mapping, 
    - metric and semantic representations for mapping, 
    - theoretical performance guarantees, 
    - active SLAM and exploration, 
    - and other new frontiers. 


 - ìµœì¢… ì§ˆë¬¸ : Do robots need SLAM? and Is SLAM solved?
 
 
 ## I. INTRODUCTION
 
- SLAM comprises the simultaneous  
    - ìƒíƒœ ì¸¡ì • : estimation of the **state of a robot** equipped with on-board sensors, 
    - ì§€ë„ ìƒì„± : the construction of a **model (the map)** of the environment that the sensors are perceiving. 

###### In simple instances,

- ë¡œë´‡ ìƒíƒœëŠ” í¬ì¦ˆ`(í¬ì§€ì…˜, ë°©í–¥)`ë‚˜ ê¸°íƒ€ ì •ë³´`(ì†ë„, ì˜¤ì°¨, íŒŒë¼ë¯¸í„°)`ë¡œ í‘œí˜„ í• ìˆ˜ ìˆë‹¤.  : `the robot state is described by `
    - its pose (position and orientation), 
    - although other quantities may be included in the state, 
        - such as robot velocity,sensor biases, and calibration parameters. 


- ì§€ë„ëŠ” ëœë“œë§ˆí¬/ì¥ì• ë¬¼ ìœ„ì¹˜ë“± ê´€ì‹¬ ì˜ì—­ìœ¼ë¡œ í‘œí˜„ í• ìˆ˜ ìˆë‹¤. `The map is a representation of aspects of interest (e.g.,position of landmarks, obstacles) describing the environment in which the robot operates.`


- ì§€ë„ê°€ í•„ìš”í•œ ë‘ê°€ì§€ ì´ìœ  `The need to use a map of the environment is two fold.`
    - ì²«ì§¸ ë‹¤ë¥¸ Taskì— í™œìš©í•˜ê¸° ìœ„í•´  `First, the map is often required to support other tasks; `
        - ì˜ˆ : ê²½ë¡œ ì„¤ì •,  `for instance, a map can inform path planning or provide an intuitive visualization for a human operator. 
    - ë‘˜ì§¸, ë¡œë´‡ì˜ Stateì¸¡ì •ì‹œ ë°œìƒí•˜ëŠ” ì—ëŸ¬ë¥¼ ì œí•œ í•˜ê¸° ìœ„í•´ `Second, the map allows limiting the error committed in estimating the state of the robot. `
        - ì§€ë„ê°€ ì—†ë‹¤ë©´, dead-reckoningì´ ë¹ ë¥´ê²Œ í™•ì‚°ë ê²ƒì´ë‹¤. `In the absence of a map, dead-reckoning would quickly drift over time; `
        - ì§€ë„ê°€ ìˆë‹¤ë©´, ìœ„ì¹˜ ì—ëŸ¬ë¥¼ ì•Œë ¤ì§„ ì§€ì—­ì˜ re-visitingë¥¼ í†µí•´ ì¬ì„¤ì • ê°€ëŠ¥í•˜ë‹¤. `on the other hand, using a map, (e.g.,a set of distinguishable landmarks), the robot can â€œresetâ€ its localization error by re-visiting known areas (so-called loop closure). `

- ë”°ë¼ì„œ SLMAì€ ì§€ë„ê°€ ì—†ì–´ ìƒì„±í•´ì•¼ í•˜ëŠ” ì„œë¹„ìŠ¤ì—ì„œë„ í™œìš©ì´ ê°€ëŠ¥í•˜ë‹¤. `Therefore, SLAM finds applications in all scenarios in which a prior map is not available and needs to be built.`


- ì¼ë¶€ í™˜ê²½ì—ì„œëŠ” ëœë“œë§ˆí¬ê°€ ë¯¸ë¦¬ ì •ì˜ë˜ì–´ ìˆë‹¤. `In some robotics applications the location of a set of landmarks is known a priori. `
    - ì˜ˆë¥¼ ë“¤ì–´ ë¹„ì½˜ë“±ì„ ì´ìš©í•˜ì—¬ ìœ„ì¹˜ ì •ë³´ë¥¼ ë¯¸ë¦¬ ì•Œë ¤ ì¤€ë‹¤. `For instance, a robot operating on a factory floor can be provided with a manually-built map of artificial beacons in the environment. `
    - ë˜ëŠ” ì‹¤ë‚´ì§€ë§Œ GPSë¥¼ ìˆ˜ì‹ í• ìˆ˜ ìˆëŠ” í™˜ê²½ë„ ëœë“œë§ˆí¬ê°€ ì•Œë ¤ì§„ê²ƒìœ¼ë¡œ ë³¼ìˆ˜ ìˆë‹¤. `Another example is the case in which the robot has access to GPS (the GPS satellites can be considered as moving beacons at known locations). `
    - ì´ëŸ° ì•Œë ¤ì§„ ëœë“œë§ˆí¬ë¥¼ ì´ìš©í•˜ì—¬ localizationì´ ê°€ëŠ¥í•œ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œëŠ” SLAMì´ ê¼­ í•„ìš” í•˜ì§€ ì•Šë‹¤. `
In such scenarios, SLAM may not be required if localization can be done reliably with respect to the known landmarks.`


- The popularity of the SLAM problem is connected with the emergence of indoor applications of mobile robotics. 
    -     
 
 ###### [1986-2004 : classical age] 
      
- 20ë…„ê°„ì˜ SLAM ë¬¸ì œ ì—°êµ¬ì— ëŒ€í•œ ì¶”ì²œ ì„œë² ì´ ë…¼ë¬¸ : [7, 69]`A thorough historical review of the first 20 years of the SLAM problem is given by Durrant-Whyte and Bailey in two surveys [7, 69]. `


- [7, 69]ì˜ ì£¼ìš” ë‚´ìš©ì€ classical age(1986-2004)ì— ëŒ€í•œ ë‚´ìš©ì´ë‹¤. `These mainly cover what we call the classical age (1986-2004); `
    - the classical age saw the introduction of the main probabilistic formulations for SLAM,
    - including approaches based on 
        - Extended Kalman Filters, 
        - RaoBlackwellised Particle Filters, 
        - and maximum likelihood estimation;
    - moreover, it delineated the basic challenges connected to efficiency and robust data association. 


- classical ageì˜ ì—°êµ¬ì˜ ì°¸ê³  ë¬¸í—Œ ë“¤ `Two other excellent references describing the three main SLAM formulations of the classical age are` 
    - the book of Thrun, Burgard, andFox [240] and 
    - the chapter of Stachniss et al. [234, Ch. 46].

###### [2004-2015 : algorithmic-analysis age] 

- ì´í›„ì˜ ì—°êµ¬ëŠ” algorithmic-analysis age (2004-2015)ë¼ê³  ë¶ˆë¦¬ìš°ê³  [64]ì— ì˜ ì„¤ëª…ë˜ì–´ ìˆë‹¤. `The subsequent period is what we call the algorithmic-analysis age (2004-2015), and is partially covered by Dissanayake etal. in [64]. `
    - The algorithmic analysis period saw the study of fundamental properties of SLAM, 
    - including 
        - observability,
        - convergence, and 
        - consistency. 
    - In this period, 
        - the key role of sparsity towards efficient SLAM solvers was also understood,
        - and the main open-source SLAM libraries were developed.





![](https://i.imgur.com/H3wV6eR.png)

- SLAM ì„œë² ì´ ë…¼ë¬¸ë“¤ì„ í‘œ 1ì— ì •ë¦¬ í•˜ì˜€ë‹¤. ìµœê·¼ ì„œë² ì´ ë…¼ë¬¸ë“¤ì€ íŠ¹ì • aspectsì´ë‚˜ SLMAì˜ sub-fieldsì— ì´ˆì ì„ ë‘ê³  ìˆì—ˆë‹¤. ` We review the main SLAM surveys to date in Table I,observing that most recent surveys only cover specific aspects or sub-fields of SLAM. `


- ì§€ë‚œ 30ë…„ê°„ SLAMì´ ì¸ê¸° ìˆì—ˆë˜ê²ƒì€ SLAMì´ í¬í•¨í•˜ëŠ” aspects ë§Œ ë´ë„ ì•Œìˆ˜ ìˆë‹¤. `The popularity of SLAM in the last 30years is not surprising if one thinks about the manifold aspects that SLAM involves. `
    - At the lower level (called the front-end in Section II) SLAM naturally intersects other research fields such as 
        - computer vision and 
        - signal processing; 
    - at the higher level (that we later call the back-end), SLAM is an appealing mix of 
        - geometry, 
        - graph theory, 
        - optimization, 
        - and probabilistic estimation. 
    - Finally, a SLAM expert has to deal with practical aspects ranging 
        - from sensor calibration 
        - to system integration. 


- ìµœê·¼ ë…¼ë¬¸ ë“¤ì€ SLAMì— ëŒ€í•œ ì˜¤ë²„ë·°ì™€ ì—°êµ¬ ë°©í–¥ì„ ì œì‹œ í•˜ê³  ìˆë‹¤. `The present paper gives a broad overview of the current state of SLAM, and offers the perspective of part of the community on the open problems and future directions for the SLAM research. `

- ìš°ë¦¬ì˜ ì£¼ ê´€ì‹¬ì€ **metric**ê³¼ **semantic SLAM**ì´ë‹¤. ì¶”ì²œí•  ë§Œí•œ ì„œë² ì´ë…¼ë¬¸ì€ [160]ì´ë‹¤. `Our main focus is on metric and semantic SLAM, and we refer the reader to the recent survey by Lowry etal. [160],`
    - ì´ë…¼ë¬¸ì€ ë¹„ì ¼ ê¸°ë°˜ place recognitionê³¼ topological SLAMì— ëŒ€í•˜ì—¬ ë‹¤ë£¨ê³  ìˆë‹¤. ` which provides a comprehensive review of vision based place recognition and topological SLAM.`
    
```
[160] S. Lowry, N. Sunderhauf, P. Newman, J. J. Leonard, D. Cox, P. Corke, and M. J. Milford. Visual Place Recognition: A Survey. IEEE Transactions on Robotics (TRO), 32(1):1â€“19, 2016.

```

### SLAMì— ëŒ€í•œ ë‘ê°€ì§€ ë…¼ì˜ ì  

- ì¢€ë” ê¹Šê²Œ ë“¤ì–´ ê°€ê¸° ì „ì— ì•„ë˜ ë‘ ë¬¼ìŒì— ëŒ€í•˜ì—¬ ì‚´í´ ë³´ì `Before delving into the paper, we first discuss two questions that often animate discussions during robotics conferences: `
    - (1) do autonomous robots need SLAM? and 
    - (2) is SLAM solved as an academic research endeavor? 
- ì´ ì§ˆë¬¸ì— ëŒ€í•˜ì—¬ì„œëŠ” í›„ë°˜ë¶€ì— ë‹¤ì‹œ ì–¸ê¸‰í•˜ê² ë‹¤. `We will revisit these questions at the end of the manuscript.`

####  Q 1 : Do autonomous robots really need SLAM?


- ì²«ë²ˆì§¸ ì§ˆë¬¸ì— ë‹µë³€í•˜ê¸° ìœ„í•´ì„œëŠ” ë¬´ì—‡ì´ SLAMì„ Uniqueí•˜ê²Œ ë§Œë“œëŠ”ì§€ ì´í•´ í•´ì•¼ í•œë‹¤. `Answering the question â€œDo autonomous robots really need SLAM?â€ requires understanding what makes SLAM unique.`

- ìŠ¬ë¨ì˜ ëª©í‘œëŠ” ê¸€ë¡œë²Œí•˜ê³  ì¼ê´€ëœ representationì„ ìƒì„± í•˜ëŠ”ê²ƒì´ë‹¤. S`LAM aims at building a globally consistent representation of the environment,`
    - leveraging both ego-motion measurements and loop closures. 

- í‚¤ì›Œë“œëŠ” loop closureì´ë‹¤. `The keyword here is â€œloop closureâ€:`
    - loop closureë¥¼ í¬ê¸° í•˜ë©´ odometryë¥¼ ì¤„ì¼ìˆ˜ ìˆë‹¤. `if we sacrifice loop closures, SLAM reduces to odometry. `

- ì´ˆì°½ê¸°ì—ëŠ” odometryëŠ” ë°”í€´ ì¸ì½”ë”ë¥¼ í†µí•´ì„œ ì–»ì—ˆë‹¤. `In early applications, odometry was obtained by integrating wheel encoders. `

- ë°”í€´ odometry ë¡œ ì˜ˆì¸¡í•œ PoseëŠ” ì‰½ê²Œ driftsë˜ì–´ ëª‡ë¯¸í„°ë§Œ ì´ë™í•˜ì—¬ë„ ì“¸ëª¨ì—†ê²Œ ëœë‹¤. `The pose estimate obtained from wheel odometry quickly drifts, making the estimate unusable after few meters[128, Ch. 6]; `


- ì´ê²ƒì´ ìŠ¤ë¨ì„ ê°œë°œí•˜ëŠ”ë° ë¬¸ì œì ì´ë‹¤. `this was one of the main thrusts behind the development of SLAM:` 
    - ëœë“œë§ˆí¬ë¥¼ ê´€ì°°í•˜ëŠ” ë°©ë²•ì€ ì´ëŸ° trajectory driftë¥¼ ì¤„ì—¬ ì£¼ê³  ë³´ì •ë„ ê°€ëŠ¥í•˜ê²Œ í•œë‹¤. `the observation of external landmarks is useful to reduce the trajectory drift and possibly correct it [185]. `
    - ìµœê·¼ì˜ odometry ì•Œê³ ë¦¬ì¦˜ì€ ë¹„ì¥¬ì–¼ ê¸°ë°˜ì´ë©° inertial ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ ë§¤ìš° ì‘ì€ ì—ëŸ¬ë¥¼ ê°€ì§„ë‹¤. ` However, more recent odometry algorithms are based on visual and inertial information, and have very small drift(< 0.5% of the trajectory length [82]). `

ë”°ë¼ì„œ, ì²«ë²ˆì§¸ ì§ˆë¬¸ì€ ë‹¤ìŒê³¼ ê°™ì´ 3ê°€ì§€ë¡œ legitimateëœë‹¤. ` Hence the question becomes legitimate: do we really need SLAM? Our answer is three-fold.`

##### Q 1.1

- ìµœê·¼ 10ë…„ê°„ì˜ ìŠ¬ë¨ ì—°êµ¬ë“¤ì€ visual-inertial odometryì•Œê³ ë¦¬ì¦˜ì„ itself producedí•´ë‹¤. `First of all, we observe that the SLAM research done over the last decade has itself produced the visual-inertial odometry algorithms that currently represent the state of the art, e.g., [163, 175];` 

- ì´ëŸ° ê´€ì ì—ì„œ VINì€ SLAMì´ë‹¤. `in this sense Visual-Inertial Navigation(VIN) is SLAM:`
    - VINì€ loop closureê°€ ì œê±°ëœ ê°„ì†Œí™”(Reduced)ëœ SLAMì‹œìŠ¤í…œì´ë‹¤. ` VIN can be considered a reduced SLAM system, in which the loop closure (or place recognition) module is disabled. `

- SLAMì€ ì„¼ì„œ í“¨ì „ì— ëŒ€í•œ ì—°êµ¬ë¥¼ ì´ëŒì–´ ì™”ë‹¤. `More generally, SLAM has directly led to the study of sensor fusion under more challenging setups (i.e., no GPS, low quality sensors) than previously considered in other literature (e.g., inertial navigation in aerospace engineering).`

##### Q 1.2

- ë‘ë²ˆì§¸ ëŒ€ë‹µì€ true topologyì— ê´€í•œ ê²ƒì´ë‹¤. `The second answer regards the true topology of the environment.`

![](https://i.imgur.com/0KbpSfo.png)

```
[Fig. 1: Left:]
- map built from odometry. 
- The map is homotopic to a long corridor that goes from the starting position A to the final position B. 
- Points that are close in reality (e.g., B and C) may be arbitrarily far in the odometric map.

[Fig. 1: Right:]
- map build from SLAM. 
- By leveraging loop closures, SLAM estimates the actual topology of the environment, and â€œdiscoversâ€ shortcuts in the map.
```

- odometryë¥¼ ìˆ˜í–‰í•˜ë©° LCë¥¼ ë¬´ì‹œí•˜ë©´ ë¡œë´‡ì€ ì„¸ìƒì„ â€œinfinite corridorâ€ë¡œ ê°„ì£¼ í•˜ê²Œ ëœë‹¤. `A robot performing odometry and neglecting loop closures interprets the world as an â€œinfinite corridorâ€ (Fig. 1-left) in which the robot keeps exploring new areas indefinitely.`


-LCëŠ” ë¡œë´‡ì—ê²Œ corridorê°€ ê²¹ì¹˜ëŠ”ê±¸ ì•Œë ¤ ì¤€ë‹¤. `A loop closure event informs the robot that this â€œcorridorâ€keeps intersecting itself (Fig. 1-right). `

- LCì˜ ì¥ì ì€ ë‹¤ìŒê³¼ ê°™ë‹¤. `The advantage of loopclosure now becomes clear: by finding loop closures,`
    - í† í´ë¡œì§€ë¥¼ ì´í•´ í• ìˆ˜ìˆê³  `the robot understands the real topology of the environment, `
    - ìµœë‹¨ ê²½ë¡œë¥¼ ê³„ì‚° í• ìˆ˜ ìˆë‹¤. `and is able to find shortcuts between locations (e.g., point Band C in the map). `

- ë”°ë¼ì„œ ì •í™•í•œ í† í´ë¡œì§€ë¥¼ ì•„ëŠ”ê²Œ SLAMì˜ ì¥ì  ì´ë¼ë©´ ì™œ metricë¥¼ dropí•˜ê³  ë‹¨ìˆœíˆ place recognitionë§Œ í•˜ì§€ ì•ŠëŠ” ê²ƒì¸ê°€? `Therefore, if getting the right topology of the environment is one of the merits of SLAM, why not simply drop the metric information and just do place recognition? `
    - ë‹µë³€ì€ ê°„ë‹¨í•˜ë‹¤. Metricì •ë³´ëŠ” place recognitionë¥¼ ì‰½ê²Œ í•˜ë„ë¡ ë„ì™€ ì£¼ë©´ ê°•ê±´ì„±ì´ ì¦ê°€ í•œë‹¤. `The answer is simple: the metric information makes place recognition much simpler and more robust; `
    - metric reconstructionëŠ” ë¡œë´‡ì—ê²Œ LCê°€ ê°€ëŠ¥í•˜ê²Œ í•œë‹¤. `the metric reconstruction informs the robot about loop closure opportunities and allows discarding spurious loop closures [150].`

- Therefore, while SLAM might be redundant in principle (an oracle place recognition module would suffice for topological mapping), SLAM offers a natural defense against wrong data association and perceptual aliasing, where similarly looking scenes, corresponding to distinct locations in the environment,would deceive place recognition. 

- In this sense, the SLAM map provides a way to predict and validate future measurements:we believe that this mechanism is key to robust operation


##### Q 1.3 

- ì„¸ë²ˆì§¸ ëŒ€ë‹µì€ SLAMì€ globally consistent mapì„ í•„ìš”ë¡œ í•˜ëŠ” ë§ì€ ì„œë¹„ìŠ¤ì— í•„ìš”ë¡œ í•œë‹¤. `The third answer is that SLAM is needed for many applications that, either implicitly or explicitly, do require a globally consistent map. `

- ì˜ˆë¥¼ ë“¤ì–´ ëŒ€ë¶€ë¶„ì˜ ë¡œë´‡ì˜ ëª©í‘œëŠ” ì£¼ë³€ì„ ëŒì•„ ë‹¤ë‹ˆë©´ì„œ ì§€ë„ë¥¼ ì‚¬ìš©ìì—ê²Œ ì „ë‹¬ í•˜ëŠ” ê²ƒì´ë‹¤. `For instance, in many military and civilian applications, the goal of the robot is to explore an environment and report a map to the human operator, ensuring that full coverage of the environment has been obtained.`

- ë˜ ë‹¤ë¥¸ ì˜ˆë¡œëŠ” êµ¬ì¡°ë¬¼ì— ëŒ€í•œ ê²€ì‚¬ë¥¼ í•˜ëŠ” ë¡¯ë´‡ì´ë‹¤. ì´ ê²½ìš°ì— **globally consistent 3D reconstruction**ëŠ” ê¼­ í•„ìš” í•˜ë‹¤. `Another example is the case in which the robot has to perform structural inspection (of a building, bridge, etc.); also in this case a globally consistent 3D reconstruction is a requirement for successful operation.`

#### Q 2 : is SLAM solved?

- ì´ ì§ˆë¬¸ì€ ë¡œë³´í‹±ìŠ¤ ì»¤ë®¤ë‹ˆí‹°ì—ì„œ ìì£¼ íšŒì ë˜ëŠ” ì§ˆë¬¸ì´ë‹¤. `This question of â€œis SLAM solved?â€ is often asked within the robotics community, c.f. [87]. `

- ì´ ì§ˆë¬¸ì€ íŠ¹ì •í™˜ê²½/ë¡œë´‡/ì„±ëŠ¥ì— ë”°ë¼ ë‹¤ë¥´ë¯€ë¡œ ë‹µë³€í•˜ê¸° ì–´ë ¤ìš´ ì£¼ì œì´ë‹¤. `This question is difficult to answer because SLAM has become such abroad topic that the question is well posed only for a given robot/environment/performance combination. `


- SLAMê¸°ìˆ ì´ ì™„ë²½í•œì§€ í‰ê°€ í•˜ë ¤ë©´ ì•„ë˜ ì‚¬í•­ë“¤ì— ëŒ€í•˜ì—¬ ì •ì˜ ë˜ì–´ì•¼ í•œë‹¤. `In particular,one can evaluate the maturity of the SLAM problem once the following aspects are specified:`
    - robot: 
        - type of motion (e.g., dynamics, maximum speed), 
        - available sensors (e.g., resolution, sampling rate), 
        - avail-able computational resources;
    - environment: 
        - planar or three-dimensional, 
        - presence of natural or artificial landmarks, 
        - amount of dynamic elements, 
        - amount of symmetry and risk of perceptual aliasing. 
        - Note that many of these aspects actually depend on the sensor-environment pair: for instance, two rooms may look identical for a 2D laser scanner (perceptual aliasing), while a camera may discern them from appearance cues;
    - performance requirements: 
        - desired accuracy in the estimation of the state of the robot, 
        - accuracy and type of representation of the environment (e.g., landmark-based or dense), 
        - success rate (percentage of tests in which the accuracy bounds are met), 
        - estimation latency, 
        - maximum operation time, 
        - maximum size of the mapped area

- ì˜ˆë¥¼ ë“¤ì–´ ì•„ë˜ ìƒí™©ì— ëŒ€í•œ SLAMì€ Matureí•˜ë‹¤ê³  ë³¼ìˆ˜ ìˆë‹¤. 
    - `For instance, mapping a 2D indoor environment with a robot equipped with wheel encoders and a laser scanner,with sufficient accuracy (< 10cm) and sufficient robustness(say, low failure rate), can be considered largely solved (an example of industrial system performing SLAM is the Kuka Navigation Solution [145]). `
    - ë¹„ìŠ·í•œ ë¹„ì ¼ ê¸°ë°˜ SLMAì—­ì‹œ Matureí•œ ì—°êµ¬ ê²°ê³¼ì´ë‹¤. `Similarly, vision-based SLAM with slowly-moving robots (e.g., Mars rovers [166], domesticrobots [114]), and visual-inertial odometry [94] can be considered mature research fields.`
  
      
- í•˜ì§€ë§Œ ë‹¤ë¥¸ ìƒí™©ì— ëŒ€í•œ SLAMì€ Matureí•˜ë‹¤ê³  ë³¼ìˆ˜ ì—†ë‹¤. `On the other hand,`
    - other robot/environment/performance combinations still deserve a large amount of fundamental research. 


- ì˜¤ëŠ˜ë‚  SLAMì•Œê³ ë¦¬ì¦˜ë“¤ì€ ë¡œë´‡ì˜ ëª¨ì…˜ì´ë‚˜ í™˜ê²½ì´ challenging í•˜ë©´ ì¢‹ì€ ì„±ê³¼ë¥¼ ë³´ì´ì§€ ì•ŠëŠ”ë‹¤. `Current SLAM algorithms can be easily induced to fail when either the motion of the robot or the environment are too challenging (e.g., fast robot dynamics, highly dynamic environments); `
    - similarly, SLAM algorithms are often unable to face strict performance requirements, 
        - e.g., high rate estimation for fast closed-loop control. 

###### [2016- : the robust-perception age] 

- ë³¸ ë…¼ë¬¸ì—ì„œëŠ” SLAMì—°êµ¬ê°€ ìƒˆë¡œìš´ ì „ê¸°ë¥¼ ë§ì´ í•˜ê³  ìˆë‹¤ê³  ë³¸ë‹¤. `In this paper, we argue that we are entering in a third era for SLAM,` 

- robust-perception ageëŠ” ì•„ë˜ì˜ ìš”êµ¬ì‚¬í•­ì„ ê°€ì§„ë‹¤. `the robust-perception age, which is characterized by the following key requirements:`

1. robust performance: 
    - the SLAM system operates with low failure rate for an extended period of time in a broad set of environments; 
    - the system includes fail-safe mechanisms and has self-tuning capabilities[[1]](#11) in that it can adapt the selection of the system parameters to the scenario.

2. high-level understanding: 
    - the SLAM system goes beyond basic geometry reconstruction to obtain a high-level understanding of the environment 
    - (e.g., high-level geometry, **semantics**, physics, affordances);

3. resource awareness: 
    - the SLAM system is tailored to the available sensing and computational resources, and provides means to adjust the computation load depending on the available resources;
    
4. task-driven perception: 
    - the SLAM system is able to select relevant perceptual information and filter out irrelevant sensor data, 
    - in order to support the task the robot has to perform; moreover, the SLAM system produces adaptive map representations, whose complexity may vary depending on the task at hand.

### ë…¼ë¬¸ êµ¬ì„± 

Paper organization. 

- Section II : ê³µì‹ ë° êµ¬ì¡° `The paper starts by presenting a standard formulation and architecture for SLAM `

- Section III : ê°•ê±´ì„± `tackles robustness in life-long SLAM. `

- Section IV : í™•ì¥ì„± `deals with scalability. `

- Section V : discusses how to represent the geometry of the environment. 

- Section VI : extends the question of the environment representation to the modeling of semantic information. 

- Section VII : ìµœê·¼ í•™ë¬¸ì  ì„±ê³¼ë¬¼ ì˜¤ë²„ë·° `provides an overview of the current accomplishments on the theoretical aspects of SLAM. `

- Section VIII : ë¬¸ì œì  `broadens the discussion and reviews the active SLAM problem in which decision making is used to improve the quality of the SLAM results. `

- Section IX : ìµœì‹  íŠ¸ëœë“œ(ì„¼ì„œ, ë”¥ëŸ¬ë‹) `provides an overview of recent trends in SLAM, including the use of unconventional sensors and deep learning. `

- Section X : ì •ë¦¬ `provides final remarks. `

Throughout the paper, we provide many pointers to related work outside the robotics community. 

Despite its unique traits, SLAM is related to problems addressed in computer vision, computer graphics, and control theory, and cross-fertilization among these fields is a necessary condition to enable fast progress.


- ë¹„ ì „ë¬¸ê°€ ë…ìë“¤ì€ [7, 69]ì„ ë¨¼ì € ì½ì–´ ë³´ê¸¸ ê¶Œí•œë‹¤. `For the non-expert reader, we recommend to read DurrantWhyte and Baileyâ€™s SLAM tutorials [7, 69] before delving in this position paper. `

```
[7] T. Bailey and H. F. Durrant-Whyte. Simultaneous Localisation and Mapping (SLAM): Part II. Robotics and Autonomous Systems (RAS), 13(3):108â€“117, 2006.

[69] H. F. Durrant-Whyte and T. Bailey. Simultaneous Localisation and Mapping (SLAM): Part I. IEEE Robotics and Automation Magazine, 13(2):99â€“110, 2006.
```

## II. ANATOMY OF A MODERN SLAM SYSTEM

- The architecture of a SLAM system includes two main components: 
    - the front-end 
    - the back-end. 

![](https://i.imgur.com/ZX089mc.png)
```
[Fig. 2: Front-end and back-end in a typical SLAM system.]
-  The back-end can provide feedback to the front-end for loop closure detection and verification.
```

- **The front-end** abstracts sensor data into models that are amenable for estimation, 

- **The back-end** performs inference on the abstracted data produced by the front-end. 

### 2.1 Maximum a posteriori (MAP) estimation and the SLAM back-end.

- SLAMì˜ ê³µì‹ë“¤ì€ [161], [101]ì„ ê¸°ë°˜ì„ ë‘ê³  ìˆë‹¤. `The current de-facto standard formulation of SLAM has its origins in the seminal paper of Lu and Milios [161], followed by the work of Gutmann and Konolige [101].`

- ìœ„ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ê°œì„ ëœ ë°©ì‹[63, 81, 100, 125, 192, 241]ë“¤ì´ ì œì•ˆ ë˜ì—ˆë‹¤. `Since then, numerous approaches have improved the efficiency and robustness of the optimization underlying the problem[63, 81, 100, 125, 192, 241]. `

All these approaches formulate SLAM as a maximum a posteriori estimation problem, and often use the formalism of factor graphs [143] to reason about the interdependence among variables.

Assume that we want to estimate an unknown variable X ; as mentioned before, in SLAM the variable X typically includes the trajectory of the robot (as a discrete set of poses) and the position of landmarks in the environment. 

We are givena set of measurements Z = {zk : k = 1, . 

. 

. 

, m} such thateach measurement can be expressed as a function of X , i.e.,zk = hk(Xk)+k, where Xk âŠ† X is a subset of the variables,hk(Â·) is a known function (the measurement or observationmodel), and k is random measurement noise.

### 2.2 Sensor-dependent SLAM front-end



## III. LONG-TERM AUTONOMY I: ROBUSTNESS


## IV. LONG-TERM AUTONOMY II: SCALABILITY


---

<a name="11">[1]</a> The SLAM community has been largely affected by the â€œcurse of manual tuningâ€, in that satisfactory operation is enabled by expert tuning of the system parameters (e.g., stopping conditions, thresholds for outlier rejection).  <br/>




Indoor operation rules out the use of GPS to bound the localization error; furthermore, SLAM provides an appealing alternative to user-built maps, showing that robot operation is possible in the absence of an ad hoc localization infrastructure.
<!--stackedit_data:
eyJoaXN0b3J5IjpbMTY1NzU5MTc4OV19
-->