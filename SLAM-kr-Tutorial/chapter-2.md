# 제2장. SLAM과의 첫 만남.

- 주요목표 : 시각적 SLAM 프레임 워크로 구성되는 모듈과 각 모듈의 태스크가 무엇인지 이해하도록 합니다.


## 2.1 서론 : 작은 로봇의 예

자율 주행을 위해 필요한 정보 
- 나는 어디 있습니까? - 포지셔닝 (Positioning)
- 주변 환경은 어떻습니까? - 맵핑 (Mapping)


### A. Visual SLAM에 사용되는 카메라 종류 

#### 가. 단안 카메라 

- 카메라 하나만 사용하는 것을 Monocular SLAM이라고합니다.
- 2차원에서 3차원 세계를 반영합니다. - 거리 정보 상실 
- 3차원 구조를 복원하려면 카메라의 화각을 변경해야합니다.
    - 카메라를 움직여 움직임을 추정하고 장면에서 물체의 거리와 크기를 추정해야 합니다.
    - 시차를 통해 우리는 어느 물체가 멀리 떨어져 있고 어느 물체가 가까운지를 결정할 수 있습니다.
- 진정한 스케일을 확인할 수없는 문제 발생 
    - 양안 카메라로 해결
    - 깊이 카메라로 해결 
    
#### 나. 양안 카메라 

- 거리를 측정하고 단안 카메라가 거리를 알 수 없다는 단점을 극복

- 두 카메라의 거리(baseline) 정보를 기반으로 깊이를 추정 
    - 베이스 라인의 거리가 멀수록 먼 거리를 측정 할 수 있음
- 많은 계산능력 필요 
- 실내외 모두 사용 가능 

#### 다. 깊이 카메라 

- 2010년 출시 
- 적외선 구조광 방식 또는 레이저 광선의 비행 시간(Time-of-Flight)을 측정해 깊이 값을 예측
- 양안 대비 계산력이 적음 
- 단점 : 좁은 범위, 높은 노이즈, 작은 시야, 햇빛에 쉽게 노출, 투과 물질 측정 불가


## 2.2 고전적인 시각적 SLAM 프레임워크

![](https://i.imgur.com/djkhm7Y.png)

1. 센서 정보를 읽습니다. 
    - 시각적 SLAM에서는 주로 카메라 이미지 정보의 읽기 및 전처리 단계를 말합니다. 
    - 이 단계에서는 휠 및 관성 센서와 같은 정보를 읽고 동기화 할 수 있습니다.
2. Visual odometry (VO). 
    - Visual odometry는 인접한 이미지 사이의 카메라 동작과 로컬 맵의 모양을 추정하는 것입니다. 
    - VO는 프론트 엔드 라고도합니다.
3. Backend optimization
    - 백엔드는 위 그림에서 loop closure에 대한 정보는 물론 시각적 인 주행 거리계로 측정 한 카메라 포즈를 다른 시간에 받아들이고 일관된 궤도와 맵을 얻을 수 있도록 최적화합니다. 
    - VO에 연결되어 있기 때문에 Backend라고도합니다.
4. Loop Closure는 로봇이 과거에 도달했던 위치에 도달했는지 확인하는 역할을 수행합니다. 
    - loop closure가 감지되면 처리를 위해 백엔드에 정보를 제공합니다.
5. 맵핑. 추정 된 궤도를 기반으로 현재 위치에 해당하는 지도를 만듭니다.


### A. Visual Odometry

- Visual odometry는 인접한 이미지 사이의 카메라 움직임과 관련이 있습니다. 
    - 가장 간단한 경우는 두 이미지 간의 모션 관계입니다.



























