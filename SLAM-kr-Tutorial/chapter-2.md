# 제2장. SLAM과의 첫 만남.

- 주요목표 : 시각적 SLAM 프레임 워크로 구성되는 모듈과 각 모듈의 태스크가 무엇인지 이해하도록 합니다.


## 2.1 서론 : 작은 로봇의 예

자율 주행을 위해 필요한 정보 
- 나는 어디 있습니까? - 포지셔닝 (Positioning)
- 주변 환경은 어떻습니까? - 맵핑 (Mapping)


### A. Visual SLAM에 사용되는 카메라 종류 

#### 가. 단안 카메라 

- 카메라 하나만 사용하는 것을 Monocular SLAM이라고합니다.
- 2차원에서 3차원 세계를 반영합니다. - 거리 정보 상실 
- 3차원 구조를 복원하려면 카메라의 화각을 변경해야합니다.
    - 카메라를 움직여 움직임을 추정하고 장면에서 물체의 거리와 크기를 추정해야 합니다.
    - 시차를 통해 우리는 어느 물체가 멀리 떨어져 있고 어느 물체가 가까운지를 결정할 수 있습니다.
- 진정한 스케일을 확인할 수없는 문제 발생 
    - 양안 카메라로 해결
    - 깊이 카메라로 해결 
    
#### 나. 양안 카메라 

- 거리를 측정하고 단안 카메라가 거리를 알 수 없다는 단점을 극복

- 두 카메라의 거리(baseline) 정보를 기반으로 깊이를 추정 
    - 베이스 라인의 거리가 멀수록 먼 거리를 측정 할 수 있음
- 많은 계산능력 필요 
- 실내외 모두 사용 가능 

#### 다. 깊이 카메라 

- 2010년 출시 
- 적외선 구조광 방식 또는 레이저 광선의 비행 시간(Time-of-Flight)을 측정해 깊이 값을 예측
- 양안 대비 계산력이 적음 
- 단점 : 좁은 범위, 높은 노이즈, 작은 시야, 햇빛에 쉽게 노출, 투과 물질 측정 불가




